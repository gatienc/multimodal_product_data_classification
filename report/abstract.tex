\chapter*{Abstract}
\label{sec:abstract}

This report delves into the innovative realm of multimodal product classification, a critical aspect of modern e-commerce efficiency. With the rapid expansion of online marketplaces, the challenge of accurately categorizing an extensive array of products has become increasingly complex. Our focus is the case study of Rakuten, a global e-commerce leader, which faces the unique challenge of classifying a diverse range of products in its expansive marketplace.

The primary objective of this project is to develop a robust model capable of accurately categorizing products based on both textual and visual data. We explore a multimodal approach, leveraging the strengths of OpenAI's CLIP (Contrastive Languageâ€“Image Pretraining) model for feature extraction from both product images and textual descriptions. This method is instrumental in recognizing  relationships between text and images, enhancing the classification process.

The evaluation of the model's performance, based on a weighted-F1 score, demonstrates its effectiveness in accurately classifying products into predefined categories.

In conclusion, the "Multimodal Product Data Classification" report presents a compelling case for the adoption of advanced multimodal approaches in tackling the challenges of product classification in e-commerce. 



