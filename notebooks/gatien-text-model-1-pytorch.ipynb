{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# import for NLP\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount the drive where your dataset is available\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "filepath='/content/drive/MyDrive/datasets/multimodal_product_classification/' # add your own path. Where to save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train = pd.read_csv(filepath+'X_train.csv')\n",
    "y_train = pd.read_csv(filepath+'Y_train.csv')\n",
    "X_train=X_train.drop(columns=\"Unnamed: 0\")\n",
    "y_train=y_train.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and Preprocessing Text\n",
    "def clean_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-ZäöüßÄÖÜ ]', '', text)\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning function to the 'designation' column\n",
    "X_train['designation'] = X_train['designation'].fillna('').apply(clean_text)\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train['designation'])\n",
    "sequences = tokenizer.texts_to_sequences(X_train['designation'])\n",
    "\n",
    "# Padding to max length of text\n",
    "data = pad_sequences(sequences, maxlen=34)\n",
    "\n",
    "# Assuming the number of unique words in the tokenizer plus 1 is vocab_size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model\n",
    "class CNN_classifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes):\n",
    "        super(CNN_classifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv_blocks = nn.ModuleList([\n",
    "            nn.Conv2d(1, 512, (i, embedding_dim), padding=(i-1, 0))\n",
    "            for i in range(1, 7)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(512 * 6, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)  # Add channel dimension for Conv2d\n",
    "        conv_outputs = [nn.functional.relu(conv_block(x)).max(dim=3)[0] for conv_block in self.conv_blocks]\n",
    "        x = torch.cat(conv_outputs, dim=1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the model\n",
    "embedding_dim = 300\n",
    "num_classes = 27\n",
    "model = CNN_classifier(vocab_size, embedding_dim, num_classes)\n",
    "\n",
    "# Print the model summary\n",
    "print(model)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Convert the model to CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Print the model summary\n",
    "print(model)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
